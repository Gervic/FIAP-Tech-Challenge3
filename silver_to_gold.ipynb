{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 5.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.functions import *\nfrom functools import reduce",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "def read_s3_file(bucket_name:str, file_path:str)-> DataFrame:\n  \"\"\"\n  Function used to read files from a s3 bucket\n  args:\n    bucket_name: Name of the s3 bucket\n    file_path: Path of the file to be read\n  returns:\n    DataFrame with the file content\n  \"\"\"\n  return spark.read.parquet(f\"s3a://{bucket_name}/{file_path}/\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "silver_bucket_name = 'project-pnad-covid-ibge-silver-layer'\ngold_bucket_name = 'project-pnad-covid-ibge-gold-layer'\npath_silver_df = 'pnad_covid_datasets_cleaned_transformed_unified'\npath_gold_df = 'pnad_covid_datasets_aggregated'\ncatalogDatabase = 'big_data_project'\ncatalogTableName = 'curated_pnad_covid_datasets'",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "silver_df = spark.read.parquet(f\"s3a://{silver_bucket_name}/{path_silver_df}/\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "silver_agregated = (silver_df\n                     .groupBy('month', \n                              'unidade_federacao', \n                              'capital_uf', \n                             )\n                    .pivot(\"question_description\")\n                    .agg(collect_list('question_answer').alias('question_answer'))\n                )",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "cols_to_considered = [\n                        'teve_febre',\n                        'teve_tosse',\n                        'teve_dor_no_peito',\n                        'teve_dor_de_garganta',\n                        'teve_dor_de_cabeca',\n                        'teve_nausea',\n                        'teve_dificuldade_para_respirar',\n                        'teve_nariz_entupido_ou_escorrendo',\n                        'teve_fadiga',\n                        'teve_dor_nos_olhos',\n                        'teve_perda_de_cheiro_ou_sabor',\n                        'teve_dor_muscular',\n                        'teve_diarreia',\n                        'recuperacao_sintomas_em_casa',\n                        'providencia_recuperacao_sintomas_procurar_profissional_saude',\n                        'recuperacao_sintomas_por_remedios_auto_medicado',\n                        'recuperacao_sintomas_por_remedios_medicado',\n                        'recuperacao_sintomas_por_sus_a_domicilio',\n                        'recuperacao_sintomas_por_medico_particular_a_domicilio',\n                        'providencia_recuperacao_sintomas_foi_outra',\n                        'buscou_atendimento_ubs',\n                        'buscou_atendimento_ps_sus_upa',\n                        'buscou_atendimento_hospital_sus',\n                        'buscou_atendimento_ambulantorio_forcas_armadas',\n                        'buscou_atendimento_ps_privado_forcas_armadas',\n                        'ficou_internado_por_1dia_ou_mais',\n                        'foi_sedado_entubado_com_respiracao_artificial',\n                        'tem_plano_de_saude',\n                        'fez_algum_test_covid',\n                        'fez_exame_cotonete_swab',\n                        'fez_exame_sangue_do_furo_no_dedo',\n                        'fez_exame_sangue_veia_braco',\n                        'ja_teve_diagnostico_diabetes',\n                        'ja_teve_diagnostico_hipertensao',\n                        'ja_teve_doenca_respiratoria',\n                        'ja_teve_diagnostico_depressao',\n                        'ja_teve_diagnostico_cancer',\n                        'ja_teve_diagnostico_doencas_coracao',\n                        'trabalhou_fez_algum_bico_na_semana_anterior',\n                        'ficou_afastado_temporiaramente_do_trabalho_na_semana_anterior',\n                        'foi_remunerado_nesse_periodo',\n                        'tem_mais_de_um_trabalho',\n                        'carteira_assinada_ou_funcionario_estatutario',\n                        'home_office_na_semana_passada',\n                        'contribuidor_inss',\n                        'fez_emprestimo_na_pandemia',\n                        'emprestimo_em_banco_ou_financeira',\n                        'tem_itens_basico_de_limpeza_em_casa', \n                        'resultado_exame_swab', \n                        'resultado_exame_sangue_do_furo_no_dedo', \n                        'resultado_exame_sangue_veia_braco',\n                        'tipo_de_area',\n                         'cor_ou_raca',\n                         'sexo',\n                         'faixa_etaria',\n                         'setor_da_empresa_do_trabalho',\n                         'trabalho_setor_privado_ou_publico',\n                         'tipo_trabalho_ou_cargo',\n                         'escolaridade',\n                         'tipo_escola_faculdade',\n                         'situacao_do_domicilio',\n                         'idade_do_morador'\n                    ]",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 25,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_list = []\nfor c in cols_to_considered:\n    try:\n        df = (silver_agregated\n              .select('month', \n                      'unidade_federacao', \n                      'capital_uf', \n                      explode(col(c)).alias(c)\n                     )\n            )\n        df_list.append(df)\n    except:\n        continue",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 26,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def merge_df(list_df: list):\n    return reduce(lambda df1, df2: df1.join(df2, ['month', 'unidade_federacao', 'capital_uf'], 'full'), list_df)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 27,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_gold = merge_df(df_list)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 28,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "list_cols_to_aggregated2 = ['resultado_exame_swab', \n                            'resultado_exame_sangue_do_furo_no_dedo', \n                            'resultado_exame_sangue_veia_braco'\n                            ]\nto_ignore = ['tipo_de_area',\n             'cor_ou_raca',\n             'sexo',\n             'faixa_etaria',\n             'setor_da_empresa_do_trabalho',\n             'trabalho_setor_privado_ou_publico',\n             'tipo_trabalho_ou_cargo',\n             'escolaridade',\n             'tipo_escola_faculdade',\n             'situacao_do_domicilio',\n              'idade_do_morador',\n             'month', \n             'unidade_federacao', \n             'capital_uf'\n        ]\n\nlist_cols_to_aggregated = [c for c in df_gold.columns if c not in list_cols_to_aggregated2 and c not in to_ignore]",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 34,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "agg_list = []\nfor c in list_cols_to_aggregated:\n    case_sim = when(col(c) == 'sim', 1).otherwise(0)\n    case_nao = when(col(c) == 'nao', 1).otherwise(0)\n    case_nao_sabe = when(col(c) == 'nao_sabe', 1).otherwise(0)\n    case_nao_aplicavel = when(col(c) == 'nao_aplicavel', 1).otherwise(0)\n\n    agg_list.append(sum(case_sim).alias(f'qtd_pessoas_sim_para_{c}'))\n    agg_list.append(sum(case_nao).alias(f'qtd_pessoas_nao_para_{c}'))\n    agg_list.append(sum(case_nao_sabe).alias(f'qtd_pessoas_nao_sabe_para_{c}'))\n    agg_list.append(sum(case_nao_aplicavel).alias(f'qtd_pessoas_nao_aplicavel_para_{c}'))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 35,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "for c in list_cols_to_aggregated2:\n    case_positivo = when(col(c) == 'Positivo', 1).otherwise(0)\n    case_negativo = when(col(c).isin('Negativo', 'Inconclusivo'), 1).otherwise(0)\n    agg_list.append(sum(case_positivo).alias(f'qtd_pessoas_positivo_para_{c}'))\n    agg_list.append(sum(case_negativo).alias(f'qtd_pessoas_negativo_para_{c}'))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 36,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_gold_aggregated = (df_gold\n                    .withColumn('faixa_etaria', when(col('idade_do_morador').cast('int') <= 25, '0-18')\n                                .when((col('idade_do_morador').cast('int') > 18) & (col('idade_do_morador').cast('int') <= 35), '18-35')\n                                .when((col('idade_do_morador').cast('int') > 35) & (col('idade_do_morador').cast('int') <= 45), '36-45')\n                                .when((col('idade_do_morador').cast('int') > 45) & (col('idade_do_morador').cast('int') <= 55), '46-55')\n                                .when((col('idade_do_morador').cast('int') > 55) & (col('idade_do_morador').cast('int') <= 65), '56-65')\n                                .when(col('idade_do_morador').cast('int') > 65, '65+')\n                                .otherwise('Unknown')\n                                )\n                        .groupBy('month', \n                                 'unidade_federacao', \n                                 'tipo_de_area',\n                                 'cor_ou_raca',\n                                 'sexo',\n                                 'faixa_etaria',\n                                 'setor_da_empresa_do_trabalho',\n                                 'trabalho_setor_privado_ou_publico',\n                                 'tipo_trabalho_ou_cargo',\n                                 'escolaridade',\n                                 'tipo_escola_faculdade',\n                                 'situacao_do_domicilio'\n                                )\n                        .agg(*agg_list)\n                    )                       ",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 37,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Write the data in the DynamicFrame to a location in Amazon S3 and a table for it in the AWS Glue Data Catalog\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "from awsglue.dynamicframe import DynamicFrame\ndynamic_frame = DynamicFrame.fromDF(df_gold_aggregated, glueContext, \"dynamic_frame\")\n\ns3output = glueContext.getSink(\n  path = f\"s3://{gold_bucket_name}/{path_gold_df}\",\n  connection_type=\"s3\",\n  updateBehavior=\"UPDATE_IN_DATABASE\",           # Important for catalog creation\n  partitionKeys=['month'],                       # Optional: specify if you want partitions\n  compression=\"snappy\",                          # Recommended for Parquet\n  enableUpdateCatalog=True,                      # This triggers Glue Catalog update/create\n  transformation_ctx=\"s3output\",\n)\n\ns3output.setCatalogInfo(\n  catalogDatabase=catalogDatabase,               # Glue database (must exist)\n  catalogTableName=catalogTableName              # Table will be created if not existing\n)\n\ns3output.setFormat(\"glueparquet\")                # Recommended format for Glue compatibility\ns3output.writeDynamicFrame(dynamic_frame) ",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}