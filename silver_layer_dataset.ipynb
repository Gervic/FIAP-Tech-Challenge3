{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4k6nhTy9DKRMEKKQmGYIC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Introduction\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The following notebook is part of data pipeline project using the medallion architecture. <br>\n",
        "In this notebook, we have developed the ETL process for the project silver layer. So, the result will be saved in a s3 bucket and used to develop our gold layer. An important detail is that the script has been created to run in Aws Glue.\n"
      ],
      "metadata": {
        "id": "aWIjsIJ3919E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries, Environment variables and Spark config\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Z1SPnyqe5pmW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2xx3byQDhuJ",
        "outputId": "e69c281a-a1a9-46bc-ea6a-103813ab6c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (1.37.18)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.11/dist-packages (1.3.8)\n",
            "Requirement already satisfied: botocore<1.38.0,>=1.37.18 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.37.18)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3) (0.11.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.18->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.18->boto3) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.18->boto3) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install findspark boto3 unidecode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import DataFrame\n",
        "from functools import reduce\n",
        "import findspark\n",
        "import unidecode\n",
        "import boto3\n",
        "import os\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "ejaZNBgQDlga"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AKIAUZNHGYOJQTT4ZXPY\"\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"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\"\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"\n",
        "\n",
        "aws_access_key_id = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
        "aws_secret_access_key = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
        "region_name = os.environ.get(\"AWS_DEFAULT_REGION\")\n",
        "\n",
        "spark = (SparkSession.builder\n",
        "        .appName(\"ColabS3Upload\")\n",
        "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
        "        .config(\"spark.hadoop.fs.s3a.access.key\", aws_access_key_id)\n",
        "        .config(\"spark.hadoop.fs.s3a.secret.key\", aws_secret_access_key)\n",
        "        .config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\")\n",
        "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4\")\n",
        "        .getOrCreate()\n",
        "      )"
      ],
      "metadata": {
        "id": "fT6UpSgPDldd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions to read, transform and upload transformed files\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "EJq2aMH15YIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_s3_file(bucket_name:str, file_path:str)-> DataFrame:\n",
        "  \"\"\"\n",
        "  Function used to read files from a s3 bucket\n",
        "  args:\n",
        "    bucket_name: Name of the s3 bucket\n",
        "    file_path: Path of the file to be read\n",
        "  returns:\n",
        "    DataFrame with the file content\n",
        "  \"\"\"\n",
        "  return spark.read.parquet(f\"s3a://{bucket_name}/{file_path}/\")"
      ],
      "metadata": {
        "id": "GwObQk6X59jt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unpivot_cols(df:DataFrame) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Function used to transform a wide dataframe to a long dataframe\n",
        "  args:\n",
        "    df: DataFrame to be unpivoted\n",
        "  returns:\n",
        "    DataFrame unpivoted\n",
        "\n",
        "  \"\"\"\n",
        "  cols_ids = ['Ano', 'UF', 'CAPITAL', 'RM_RIDE']\n",
        "  cols_to_unpivot = [col for col in df.columns if col not in cols_ids]\n",
        "  return df.melt(cols_ids, cols_to_unpivot, 'category', 'category_value')"
      ],
      "metadata": {
        "id": "pr5wCnT14U97"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pivot_df(df:DataFrame) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Function used to transform a long dataframe to a wide dataframe\n",
        "  args:\n",
        "    df: DataFrame to be pivoted\n",
        "  returns:\n",
        "    DataFrame pivoted\n",
        "\n",
        "  \"\"\"\n",
        "  return (df\n",
        "          .groupBy(\"month\", \"unidade_federacao\", \"capital_uf\", \"question_id\")\n",
        "          .pivot(\"question_description\")\n",
        "          .agg(first(\"question_answer\"))\n",
        "        )"
      ],
      "metadata": {
        "id": "yKk_zqNjO26W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cols_ids_description(df:DataFrame, df_dict:DataFrame) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Function used to add descriptions to the columns of the dataframe from a glossary dataframe\n",
        "  args:\n",
        "    df: DataFrame to be enriched with descriptions\n",
        "    df_dict: Glossary dataframe\n",
        "  returns:\n",
        "    DataFrame with descriptions added\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  uf_df = (df_dict.filter(col('codigo_variavel') == 'UF')\n",
        "              .select('categoria_variavel', 'descricao_categoria')\n",
        "          )\n",
        "\n",
        "  capital_df = (df_dict.filter(col('codigo_variavel') == 'CAPITAL')\n",
        "                .select('categoria_variavel', 'descricao_categoria')\n",
        "            )\n",
        "\n",
        "  return (df\n",
        "          .join(uf_df, df.UF == uf_df.categoria_variavel, 'left')\n",
        "          .withColumn('unidade_federacao', col('descricao_categoria'))\n",
        "          .drop(*['descricao_categoria', 'UF', 'categoria_variavel'])\n",
        "          .join(capital_df, df.CAPITAL == capital_df.categoria_variavel, 'left')\n",
        "          .withColumn('capital_uf', col('descricao_categoria'))\n",
        "          .drop(*['descricao_categoria', 'CAPITAL', 'categoria_variavel'])\n",
        "        )"
      ],
      "metadata": {
        "id": "IK7iMU194YRN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dict (df_dict:DataFrame, special_cols:list) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Function used to split the glossary dataframe into two dataframes, one with the special columns and the other with the regular columns.\n",
        "  args:\n",
        "    df_dict: DataFrame to be splitted\n",
        "    special_cols: List with the special columns\n",
        "  returns:\n",
        "    Two dataFrames with the special and regular columns respectively\n",
        "\n",
        "  \"\"\"\n",
        "  df_dict_special = (df_dict\n",
        "                    .filter(col('codigo_variavel').isin(*special_cols))\n",
        "                    .filter(col('categoria_variavel').isNotNull())\n",
        "                    .select('codigo_variavel', 'descricao_variavel')\n",
        "                    .distinct()\n",
        "                  )\n",
        "\n",
        "  df_dict_regular = (df_dict\n",
        "                    .filter(~col('codigo_variavel').isin(*special_cols))\n",
        "                    )\n",
        "  return df_dict_special, df_dict_regular"
      ],
      "metadata": {
        "id": "-soGa5t04bfy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@udf(StringType())\n",
        "def normalize_to_snake_case(text):\n",
        "    if text is not None:\n",
        "        normalized = unidecode.unidecode(text.strip().lower())  # Remove accents + lowercase\n",
        "        normalized = normalized.replace(\" \", \"_\")  # Replace spaces with underscores\n",
        "        return normalized\n",
        "    return None"
      ],
      "metadata": {
        "id": "oreD4DHFWzY8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_final(df:DataFrame, df_dict_regular:DataFrame, df_dict_special:DataFrame, special_cols:list, month:str) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Function used to add descriptions to the columns of the dataframe from two dataframes with the descriptions needed and add a month column\n",
        "  args:\n",
        "    df: DataFrame to be enriched with descriptions\n",
        "    df_dict_regular: Glossary dataframe with the regular columns\n",
        "    df_dict_special: Glossary dataframe with the special columns\n",
        "    special_cols: List with the special columns\n",
        "    month: Month of the data\n",
        "  returns:\n",
        "    DataFrame with descriptions added\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  cols_to_be_selected = ['month', 'unidade_federacao', 'capital_uf', 'question_id', 'question_description', 'question_answer']\n",
        "  df_full = (df\n",
        "            .join(df_dict_regular,\n",
        "                  (df_dict_regular.codigo_variavel == df.category)\n",
        "                  & (df_dict_regular.categoria_variavel == df.category_value),\n",
        "                  'left'\n",
        "                )\n",
        "            .withColumnsRenamed({'descricao_variavel': 'category_description1',\n",
        "                                'descricao_categoria':'value_description1'}\n",
        "                                )\n",
        "            .join(df_dict_special, (df_dict_special.codigo_variavel == df.category), 'left')\n",
        "            .withColumn('question_answer',\n",
        "                        when(col('category').isin(*special_cols), col('category_value'))\n",
        "                        .otherwise(col('value_description1'))\n",
        "                        )\n",
        "            .withColumn('question_description', coalesce(col('category_description1'), col('descricao_variavel')))\n",
        "            .withColumnRenamed('category', 'question_id')\n",
        "            .withColumn('month', lit(month))\n",
        "            .select(*cols_to_be_selected)\n",
        "          )\n",
        "  return df_full"
      ],
      "metadata": {
        "id": "BBIOQKGA4eck"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combined_dataframes(dataframes_list:list) -> DataFrame:\n",
        "  \"\"\"\n",
        "  Function to combine the dataframes from the list provided into a single dataframe\n",
        "  args:\n",
        "    dataframes_list: List of dataframes to be combined\n",
        "  returns:\n",
        "    A dataFrame combined from the list provided\n",
        "  \"\"\"\n",
        "  return reduce(DataFrame.unionAll, dataframes_list)"
      ],
      "metadata": {
        "id": "yLgFV95u4i7k"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bucket(bucket_name:str):\n",
        "  \"\"\"\n",
        "  Function to create a bucket in s3\n",
        "  args:\n",
        "    bucket_name: Name of the bucket to be created\n",
        "  \"\"\"\n",
        "  s3 = boto3.client(\n",
        "      's3',\n",
        "      aws_access_key_id= aws_access_key_id,\n",
        "      aws_secret_access_key= aws_secret_access_key,\n",
        "      region_name=region_name\n",
        "  )\n",
        "  s3.create_bucket(Bucket=bucket_name)"
      ],
      "metadata": {
        "id": "oaCy54L56Gs-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_to_s3(df:DataFrame, bucket_name:str, path:str):\n",
        "  \"\"\"\n",
        "  Function to load a dataframe in parquet format to s3\n",
        "  args:\n",
        "    df: DataFrame to be loaded\n",
        "    bucket_name: Name of the bucket to be loaded\n",
        "    path: Path to be loaded\n",
        "  \"\"\"\n",
        "  df.write.mode(\"overwrite\").parquet(f\"s3a://{bucket_name}/{path}/\")"
      ],
      "metadata": {
        "id": "IribfAdSQLYQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Excution\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "XJ8i8E-S_cdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Variables\n",
        "special_cols = ['UPA', 'V1008', 'V1012', 'V1013', 'V1016', 'Estrato',\n",
        "                'V1030', 'V1031', 'V1032', 'posest', 'A001', 'A001B1',\n",
        "                'A001B2', 'A001B3', 'A002', 'C0051', 'C0052', 'C0053',\n",
        "                'C007E2', 'C008', 'C009', 'C01012', 'C01022', 'C011A12',\n",
        "                'C011A22', 'D0013', 'D0023', 'D0033', 'D0043', 'D0053',\n",
        "                'D0063', 'D0073', 'F0021', 'F006', 'A002'\n",
        "              ]\n",
        "\n",
        "bronze_bucket_name = 'project-pnad-covid-bronze-layer'\n",
        "silver_bucket_name = 'project-pnad-covid-silver-layer'\n",
        "path_sept_file = 'PNAD_COVID_092020_parquet'\n",
        "path_oct_file = 'PNAD_COVID_102020_parquet'\n",
        "path_nov_file = 'PNAD_COVID_112020_parquet'\n",
        "path_dict_file = 'dicionario_PNAD_COVID_parquet'\n",
        "\n",
        "sept = '2020-09-01'\n",
        "oct = '2020-10-01'\n",
        "nov = '2020-11-01'\n",
        "\n",
        "path_silver_df = 'pnad_covid_datasets_cleaned_transformed_unified'"
      ],
      "metadata": {
        "id": "J2YlREVCEIZg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sept_df = read_s3_file(bronze_bucket_name, path_sept_file)\n",
        "oct_df = read_s3_file(bronze_bucket_name, path_oct_file)\n",
        "nov_df = read_s3_file(bronze_bucket_name, path_nov_file)\n",
        "glossay_df = read_s3_file(bronze_bucket_name, path_dict_file)"
      ],
      "metadata": {
        "id": "S73uxyUuESDG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unpivoting  datasets\n",
        "sept_df_unpivoted = unpivot_cols(sept_df)\n",
        "oct_df_unpivoted = unpivot_cols(oct_df)\n",
        "nov_df_unpivoted = unpivot_cols(nov_df)"
      ],
      "metadata": {
        "id": "nbC0hc2-ESAA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inserindo algumas descrições a partir do dicionário (capital e uf)\n",
        "df_sept_enriched = cols_ids_description(sept_df_unpivoted, glossay_df)\n",
        "df_oct_enriched = cols_ids_description(oct_df_unpivoted, glossay_df)\n",
        "df_nov_enriched = cols_ids_description(nov_df_unpivoted, glossay_df)"
      ],
      "metadata": {
        "id": "2clayh5_ER9M"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, we splitting the glossary dataframe in two dataframes.\n",
        "# To add descriptions to the dataframes from the glossary dataframe, we need to join them.\n",
        "# For some columns, we need two cols to join (must relate two ids) and for others only one column.\n",
        "# So either we need to seperate them or we join the glossary df twice\n",
        "# We have decided to split the df\n",
        "df_dict_special, df_dict_regular = split_dict(glossay_df, special_cols)"
      ],
      "metadata": {
        "id": "A0RqYT5FGvKG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframes fully enriched with descriptions\n",
        "df_sept_final = df_final(df_sept_enriched, df_dict_regular, df_dict_special, special_cols, sept)\n",
        "df_oct_final = df_final(df_oct_enriched, df_dict_regular, df_dict_special, special_cols, oct)\n",
        "df_nov_final = df_final(df_nov_enriched, df_dict_regular, df_dict_special, special_cols, nov)"
      ],
      "metadata": {
        "id": "9EiFdhEeER5y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unifying the dataframes into a single one\n",
        "df_list = [df_sept_final, df_oct_final, df_nov_final]\n",
        "df_full = combined_dataframes(df_list)"
      ],
      "metadata": {
        "id": "1umIxok4NuhE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing answer with null records\n",
        "df_silver = (df_full\n",
        "             .filter(col('question_description').isNotNull())\n",
        "             .filter(col('question_answer').isNotNull())\n",
        "          )"
      ],
      "metadata": {
        "id": "XbBnIdHyj_yx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-describing the question from the census made during covid pandemic\n",
        "df_silver_full = (df_silver\n",
        "                  .withColumn('question_description',\n",
        "                              when(col('question_description').like('%teve febre%'), lit('teve_febre'))\n",
        "                              .when(col('question_description').like('%teve tosse%'), lit('teve_tosse'))\n",
        "                              .when(col('question_description').like('%dor no peito%'), lit('teve_dor_no_peito'))\n",
        "                              .when(col('question_description').like('%dor de garganta%'), lit('teve_dor_de_garganta'))\n",
        "                              .when(col('question_description').like('%dor de cabeça%'), lit('teve_dor_de_cabeca'))\n",
        "                              .when(col('question_description').like('%teve náusea%'), lit('teve_nausea'))\n",
        "                              .when(col('question_description').like('%teve dificuldade para respirar%'), lit('teve_dificuldade_para_respirar'))\n",
        "                              .when(col('question_description').like('%teve nariz entupido ou escorrendo%'), lit('teve_nariz_entupido_ou_escorrendo'))\n",
        "                              .when(col('question_description').like('%teve fadiga%'), lit('teve_fadiga'))\n",
        "                              .when(col('question_description').like('%teve dor nos olhos%'), lit('teve_dor_nos_olhos'))\n",
        "                              .when(col('question_description').like('%teve perda de cheiro ou sabor%'), lit('teve_perda_de_cheiro_ou_sabor'))\n",
        "                              .when(col('question_description').like('%teve dor muscular%'), lit('teve_dor_muscular'))\n",
        "                              .when(col('question_description').like('%teve diarreia%'), lit('teve_diarreia'))\n",
        "\n",
        "                              .when(col('question_description').like('%atividades escolares para realizar em casa%'), lit('atividades_escolares_em_casa'))\n",
        "                              .when(col('question_description').like('%que frequenta é pública ou privada%'), lit('tipo_escola_faculdade'))\n",
        "                              .when(col('question_description').like('%tendo aulas presenciais%'), lit('tendo_aulas_presenciais'))\n",
        "                              .when(col('question_description').like('%realizou as atividades disponibilizadas na semana passada%'), lit('motivo_nao_realizacao_atividades_escolares'))\n",
        "                              .when(col('question_description').like('%dedicou-se às atividades escolares%'), lit('qtd_dias_dedicacao_atividades_ecolares'))\n",
        "                              .when(col('question_description').like('%para recuperar dos sintomas foi ficar em casa%'), lit('recuperacao_sintomas_em_casa'))\n",
        "                              .when(col('question_description').like('%dos sintomas foi ligar para algum profissional de saúde%'), lit('providencia_recuperacao_sintomas_procurar_profissional_saude'))\n",
        "                              .when(col('question_description').like('%dos sintomas foi comprar e/ou tomar  remédio por conta própria%'), lit('recuperacao_sintomas_por_remedios_auto_medicado'))\n",
        "                              .when(col('question_description').like('%sintomas foi comprar e/ou tomar remédio por orientação médica%'), lit('recuperacao_sintomas_por_remedios_medicado'))\n",
        "                              .when(col('question_description').like('%visita de algum profissional de saúde do SUS (equipe de saúde da família, agente comunitário, etc.)%'), lit('recuperacao_sintomas_por_sus_a_domicilio'))\n",
        "                              .when(col('question_description').like('%Providência tomada para recuperar dos sintomas foi receber visita de profissional de saúde particular%'), lit('recuperacao_sintomas_por_medico_particular_a_domicilio'))\n",
        "                              .when(col('question_description').like('%Providência tomada para recuperar dos sintomas foi outra%'), lit('providencia_recuperacao_sintomas_foi_outra'))\n",
        "                              .when(col('question_description').like('%Local que buscou atendimento foi posto de saúde%'), lit('buscou_atendimento_ubs'))\n",
        "                              .when(col('question_description').like('%Local que buscou atendimento foi pronto socorro do SUS/UPA%'), lit('buscou_atendimento_ps_sus_upa'))\n",
        "                              .when(col('question_description').like('%Local que buscou atendimento foi hospital do SUS%'), lit('buscou_atendimento_hospital_sus'))\n",
        "\n",
        "                              .when(col('question_description').like('%Local que buscou atendimento foi ambulatório ou consultório privado ou ligado às forças armadas%'), lit('buscou_atendimento_ambulantorio_forcas_armadas'))\n",
        "                              .when(col('question_description').like('%Local que buscou atendimento foi pronto socorro privado ou ligado às forças armadas%'), lit('buscou_atendimento_ps_privado_forcas_armadas'))\n",
        "                              .when(col('question_description').like('%Ao procurar o hospital, teve que ficar internado por um dia ou mais%'), lit('ficou_internado_por_1dia_ou_mais'))\n",
        "                              .when(col('question_description').like('%Durante a internação, foi sedado, entubado e colocado em respiração artificial com ventilador%'), lit('foi_sedado_entubado_com_respiracao_artificial'))\n",
        "                              .when(col('question_description').like('%Tem algum plano de saúde médico, seja particular, de empresa ou de órgão público%'), lit('tem_plano_de_saude'))\n",
        "                              .when(col('question_description').like('%algum teste para saber se estava infectado(a) pelo coronavírus?%'), lit('fez_algum_test_covid'))\n",
        "                              .when(col('question_description').like('%Fez o exame coletado com cotonete na boca e/ou nariz (SWAB)?%'), lit('fez_exame_cotonete_swab'))\n",
        "                              .when((col('question_description').like('%Qual o resultado?%')) & (trim(col('question_id')) == 'B009B'), lit('resultado_exame_swab'))\n",
        "                              .when(col('question_description').like('%Fez o exame de coleta de sangue através de furo no dedo?%'), lit('fez_exame_sangue_do_furo_no_dedo'))\n",
        "                              .when((col('question_description').like('%Qual o resultado?%')) & (trim(col('question_id')) == 'B009D'), lit('resultado_exame_sangue_do_furo_no_dedo'))\n",
        "                              .when(col('question_description').like('%Fez o exame de coleta de sangue através da veia da braço?%'), lit('fez_exame_sangue_veia_braco'))\n",
        "                              .when((col('question_description').like('%Qual o resultado?%')) & (trim(col('question_id')) == 'B009F'), lit('resultado_exame_sangue_veia_braco'))\n",
        "\n",
        "                              .when(col('question_description').like('%Algum médico já lhe deu o diagnóstico de diabetes?%'), lit('ja_teve_diagnostico_diabetes'))\n",
        "                              .when(col('question_description').like('%Algum médico já lhe deu o diagnóstico de diabetes?%'), lit('ja_teve_diagnostico_diabetes'))\n",
        "                              .when(col('question_description').like('%Algum médico já lhe deu o diagnóstico de hipertensão?%'), lit('ja_teve_diagnostico_hipertensao'))\n",
        "                              .when(col('question_description').like('%diagnóstico de asma/bronquite/enfisema/doenças respiratória crônica ou doença de pulmão?%'), lit('ja_teve_doenca_respiratoria'))\n",
        "                              .when(col('question_description').like('%Algum médico já lhe deu o diagnóstico de depressão?%'), lit('ja_teve_diagnostico_depressao'))\n",
        "                              .when(col('question_description').like('%Algum médico já lhe deu o diagnóstico de câncer?%'), lit('ja_teve_diagnostico_cancer'))\n",
        "                              .when(col('question_description').like('%Adevido à pandemia do Coronavírus, em que medida o(a) Sr(a) restringiu o contato com as pessoas?%'), lit('como_restringiu_contato_com_pessoas'))\n",
        "                              .when(col('question_description').like('%Na semana passada, por pelo menos uma hora, trabalhou ou fez algum bico?%'), lit('trabalhou_fez_algum_bico_na_semana_anterior'))\n",
        "\n",
        "                              .when(col('question_description').like('%estava temporariamente afastado de algum trabalho?%'), lit('ficou_afastado_temporiaramente_do_trabalho_na_semana_anterior'))\n",
        "                              .when(col('question_description').like('%Qual o principal motivo deste afastamento temporário?%'), lit('motivo_desse_afastamento_temporario'))\n",
        "                              .when(col('question_description').like('%Continuou a ser remunerado (mesmo que parcialmente) por esse trabalho%'), lit('foi_remunerado_nesse_periodo'))\n",
        "                              .when(col('question_description').like('%Há quanto tempo está afastado desse trabalho??%'), lit('ha_quanto_tempo_esta_afastado'))\n",
        "                              .when(col('question_description').like('%Tem mais de um trabalho?%'), lit('tem_mais_de_1_trabalho'))\n",
        "                              .when(col('question_description').like('%No trabalho (único ou principal) que tinha nessa semana, era:%'), lit('principal_ocupacao'))\n",
        "                              .when(col('question_description').like('%Esse trabalho era na área:%'), lit('trabalho_setor_privado_ou_publico'))\n",
        "                              .when(col('question_description').like('%Tem carteira de trabalho assinada ou é funcionário público estatutário?%'), lit('carteira_assinada_ou_funcionario_estatutario'))\n",
        "                              .when(col('question_description').like('%cargo ou função você realiza no seu trabalho (único ou principal)?%'), lit('tipo_trabalho_ou_cargo'))\n",
        "                              .when(col('question_description').like('%Qual é a principal atividade do local ou empresa em que você trabalha?%'), lit('setor_da_empresa_do_trabalho'))\n",
        "                              .when(col('question_description').like('%quantos empregados trabalhavam nesse negócio/empresa que ... tinha ?%'), lit('qtd_empregado_empresa'))\n",
        "                              .when(col('question_description').like('%Quantas horas, por semana, normalmente trabalhava??%'), lit('horas_de_trabalho_por_semana'))\n",
        "                              .when(col('question_description').like('%Número da faixa do rendimento/retirada em dinheiro%'), lit('faixa_de_rendimento'))\n",
        "                              .when(col('question_description').like('%Sr(a) estava em trabalho remoto (home office ou teletrabalho)%'), lit('home_office_na_semana_passada'))\n",
        "                              .when(col('question_description').like('%O(A) Sr(a) contribui para o INSS? %'), lit('contribuidor_inss'))\n",
        "                              .when(col('question_description').like('%Durante o período da pandemia alguém deste domicílio solicitou algum empréstimo?  %'), lit('fez_emprestimo_na_pandemia'))\n",
        "\n",
        "                              .when(col('question_description').like('%Este empréstimo foi adquirido com banco ou financeira%'), lit('emprestimo_em_banco_ou_financeira'))\n",
        "                              .when(col('question_description').like('%Este domicílio é: %'), lit('domicilio_proprio_alugado'))\n",
        "                              .when(col('question_description').like('%No seu domicílio há os seguintes itens básicos de limpeza e proteção: sabão ou detergente%'), lit('tem_itens_basico_de_limpeza_em_casa'))\n",
        "                              .when(col('question_description').like('%Quem respondeu ao questionário?%'), lit('quem_respondeu_o_questionario'))\n",
        "                              .when(col('question_description').like('%Qual é a principal atividade do local ou empresa em que você trabalha?%'), lit('setor_da_empresa_do_trabalho'))\n",
        "                              .otherwise(col('question_description'))\n",
        "                            )\n",
        "                  .withColumn('question_description', normalize_to_snake_case(col('question_description')))\n",
        "                )"
      ],
      "metadata": {
        "id": "x82naWTFvJnz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-describing the question answer from the census made during covid pandemic to be short and concise\n",
        "df_silver_full = (df_silver_full\n",
        "                  .withColumn('question_answer',\n",
        "                              when(col('question_answer').like('%Sim%'), lit('sim'))\n",
        "                              .when(col('question_answer').like('%Não%'), lit('nao'))\n",
        "                              .when(col('question_answer').like('%Não aplicável%'), lit('nao_aplicavel'))\n",
        "                              .when(col('question_answer').like('%Não, e meu normalmente é presencial/semipresencial%'), lit('parcialmente'))\n",
        "                              .when(col('question_answer').like('%Não, e meu normalmente é presencial/semipresencial%'), lit('semipresencial/presencial'))\n",
        "                              .when(col('question_answer').like('%Não, meu curso é online%'), lit('curso_online'))\n",
        "                              .when(col('question_answer').like('%Não tinha computador / tablet / celular disponível%'), lit('Sem equipamento'))\n",
        "                              .when(col('question_answer').like('%Tinha que cuidar dos afazeres domésticos, do(s) filhos ou de outro(s) parentes%'), lit('afazeres domesticos'))\n",
        "                              .when(col('question_answer').like('%Reduziu o contato com as pessoas, mas continuou saindo de casa para trabalho ou atividades não essenciais e/ou recebendo visitas%'), lit('Reduziu, mas continuou saindo/recebendo visitas'))\n",
        "                              .when(col('question_answer').like('%Estava em quarentena, isolamento, distanciamento social ou férias coletivas%'), lit('Quarenta/Isolamento social'))\n",
        "\n",
        "                              .when(col('question_answer').like('%Afastamento do próprio negócio/empresa por motivo de gestação, saúde, acidente%'), lit('Afastamento por motivo de gestacao/saude/acidente'))\n",
        "                              .when(col('question_answer').like('%Outro tipo de licença remunerada (estudo, paternidade, casamento, licença prêmio, etc.)%'), lit('Outro tipo de licença remunerada'))\n",
        "                              .when(col('question_answer').like('%Fatores ocasionais (mau tempo, paralisação nos serviços de transportes, etc.)%'), lit('Fatores ocasionais'))\n",
        "                              .when(col('question_answer').like('%Estava fora do mercado de trabalho (fazia apenas afazeres domésticos, cuidados de pessoas ou produção para próprio consumo)%'), lit('Estava fora do mercado de trabalho'))\n",
        "                              .when(col('question_answer').like('%Trabalhador doméstico (empregado doméstico, cuidados, babá)%'), lit('Trabalhador domestico'))\n",
        "\n",
        "\n",
        "                              .when(col('question_answer').like('%Faxineiro, auxiliar de limpeza etc. (em empresa pública ou privada)%'), lit('Auxiliar de limpeza'))\n",
        "                              .when(col('question_answer').like('%Entregador de mercadorias (de restaurante, de farmácia, de loja, Uber Eats, IFood, Rappy etc.)%'), lit('Entregador de mercadorias'))\n",
        "                              .when(col('question_answer').like('%Vendedor a domicílio, representante de vendas, vendedor de catálogo (Avon, Natura etc.)%'), lit('Vendedor a domicilio'))\n",
        "                              .when(col('question_answer').like('%Vendedor ambulante (feirante, camelô, comerciante de rua, quiosque)%'), lit('Vendedor ambulante'))\n",
        "                              .when(col('question_answer').like('%Trabalhador doméstico (empregado doméstico, cuidados, babá)%'), lit('Trabalhador domestico'))\n",
        "                              .when(col('question_answer').like('%Trabalhador doméstico (empregado doméstico, cuidados, babá)%'), lit('Trabalhador domestico'))\n",
        "                              .when(col('question_answer').like('%Trabalhador doméstico (empregado doméstico, cuidados, babá)%'), lit('Trabalhador domestico'))\n",
        "                              .otherwise(col('question_answer'))\n",
        "                            )\n",
        "\n",
        "                  .withColumn('question_answer', normalize_to_snake_case(col('question_answer')))\n",
        "                )"
      ],
      "metadata": {
        "id": "xfeRV7UekU2Z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pivoting back to wide format and making an adjustement in age column\n",
        "df_silver_final = (pivot_df(df_silver_full)\n",
        "                    .withColumn('idade_do_morador', substring('idade_do_morador', 2, 3))\n",
        "                )"
      ],
      "metadata": {
        "id": "3ytItDMxa3rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load to silver bucket\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2b-hkT6ZgShP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_bucket(silver_bucket_name)"
      ],
      "metadata": {
        "id": "OOWrwOtMS7Of"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_to_s3(df_silver_final, silver_bucket_name, path_silver_df)"
      ],
      "metadata": {
        "id": "yn7hwXutERZo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}